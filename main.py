import os
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory


    ## Functions 
def chat_w_llm(text: str, llm:object, config:dict):
    """
    Sends the input text to a language model and returns the generated response content.

    Args:
        text (str): The input text prompt to send to the language model.

    Returns:
        str: The content of the response generated by the language model.
    """
    response = llm.invoke(text, config=config)
    return response.content


def create_chat_memory():
    """
    Creates a factory function for managing chat message histories per session.
        Callable[[str], BaseChatMessageHistory]: 
            A function that retrieves the chat message history for a given session ID.
            If the session does not exist, a new in-memory chat message history is created and stored.
    Usage:
        get_session_history = create_chat_memory()
        history = get_session_history(session_id)
    """
    
    chat_history_store = {}
    def get_session_history(session_id: str) -> BaseChatMessageHistory:
        """
        Retrieve the chat message history for a given session.
        If the session does not exist in the chat history store, a new in-memory chat message history is created and stored.
        Args:
            session_id (str): The unique identifier for the chat session.
        Returns:
            BaseChatMessageHistory: The chat message history associated with the session.
        """
        if session_id not in chat_history_store:
            chat_history_store[session_id] = InMemoryChatMessageHistory()
        return chat_history_store[session_id]
    return get_session_history

def get_api_key():
    """
    Retrieves the Google API key from the environment variables.
    Loads environment variables from a .env file and attempts to fetch the value of "GOOGLE_API_KEY".
    Raises:
        EnvironmentError: If the "GOOGLE_API_KEY" is not found in the environment variables.
    Returns:
        str: The Google API key.
    """
    # load .env files
    load_dotenv()
    # define google gemini api key
    GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")
    # raise error is api key not present
    if not GOOGLE_API_KEY:
        raise EnvironmentError("Please place API key in .env file.")
    
    
def main():
    # load environment variables (ie google gemini key)
    get_api_key()
    # define the memory module, temp storage for the chat history
    memory = create_chat_memory()
    # define llm model and chat conditions
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature = 0.3)
    # Put them in the conversation chain
    llm_w_memory = RunnableWithMessageHistory(llm, memory)
    config = {"configurable": {"session_id": "123"}}
    # while loop to keep chatting
    while True:
        user_text = input("User: ")
        if user_text == "exit":
            print("Goodbye!")
            break
        response = chat_w_llm(user_text, llm_w_memory, config)
        print(f"Gemini: {response}")

# runs script only when it is executed directly
if __name__ == "__main__":
    main()
