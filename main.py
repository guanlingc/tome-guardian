import os
from dotenv import load_dotenv

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory


    ## Functions 
def chat_w_llm(text: str, llm:object, config:dict):
    """
    Sends the input text to a language model and returns the generated response content.

    Args:
        text (str): The input text prompt to send to the language model.
        config (dict): contains session id for the memory portion 

    Returns:
        str: The content of the response generated by the language model.
    """
    response = llm.invoke(text, config=config)
    return response.content


def create_chat_memory():
    """
    create a temp dictionary storage. 
    assigns a session id as KEY in the dictionary to store the chat history as VALUE
    This is implemented as the memory module needs to be a object from BaseChatMessageHistory
    Usage:
        get_session_history = create_chat_memory()
        history = get_session_history(session_id)
    """
    
    chat_history_store = {}
    def get_session_history(session_id: str) -> BaseChatMessageHistory:
        """
        Retrieve the chat message history for a given session.
        If the session does not exist in the chat history store, a new in-memory chat message history is created and stored.
        Args:
            session_id (str): The unique identifier for the chat session.
        Returns:
            BaseChatMessageHistory: The chat message history associated with the session.
        """
        if session_id not in chat_history_store:
            chat_history_store[session_id] = InMemoryChatMessageHistory()
        return chat_history_store[session_id]
    return get_session_history

def get_env_variables():
    """
    creates a dictionary with all the env variables within it.
    Loads environment variables from a .env file 
    Raises:
        EnvironmentError: If the "GOOGLE_API_KEY" is not found in the environment variables.
    Returns:
        str: The Google API key.
    """
    # load .env files
    load_dotenv()
    # define google gemini api key
    env = {
        "GOOGLE_API_KEY" : os.getenv("GOOGLE_API_KEY"),
        "GEMINI_MODEL" : os.getenv("GEMINI_MODEL")
    }
    # raise error is api key not present
    if not all(env.values()):
        raise EnvironmentError("Please place API key in .env file.")
    return env
    
    
def main():
    # load environment variables (ie google gemini key)
    env= get_env_variables()
    # define the memory module, temp storage for the chat history
    memory = create_chat_memory()
    # define llm model and chat conditions
    llm = ChatGoogleGenerativeAI(model=env["GEMINI_MODEL"], temperature = 0.3)
    # Put them in the conversation chain
    llm_w_memory = RunnableWithMessageHistory(llm, memory)
    config = {"configurable": {"session_id": "123"}}
    # while loop to keep chatting
    while True:
        # get user input 
        user_text = input("User: ")
        if user_text == "exit":
            print("Goodbye!")
            break
        # pass user input to LLM as the prompt
        response = chat_w_llm(user_text, llm_w_memory, config)
        print(f"Gemini: {response}")

# runs script only when it is executed directly
if __name__ == "__main__":
    main()
